{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Filtering and SDG Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook describes the **filtering** and **classification** of the questions generated in the previous stage.  \n",
    "The objective is to ensure question quality and assign each valid question to one or more **Sustainable Development Goals (SDGs)**.\n",
    "\n",
    "## Filtering Process\n",
    "\n",
    "Questions are evaluated according to **four metrics** defined in the referenced paper.  \n",
    "Only those satisfying **all four criteria** are retained, while the others are discarded.  \n",
    "\n",
    "Functions are provided to:\n",
    "- **Automatically apply** the filtering process to all files within a folder.  \n",
    "\n",
    "## SDG Classification\n",
    "\n",
    "Filtered questions are **classified into SDGs** to support further analysis and visualization.  \n",
    "This process can also be **executed in batch mode** to handle multiple files simultaneously.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "At the beginning of the notebook, update the **path variables** to specify the input and output directories used throughout the workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = \"Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024-prompt-1\"\n",
    "country = \"Indonesia\"\n",
    "question_path_one_file = f\"./Results/Questions/Test questions different prompts/1-Questions generated/Dev set/questions-{file_name}.json\"\n",
    "questions_path = \"./Results/Questions/Test questions different prompts/1-Questions generated/Dev set\"\n",
    "filtered_questions_path = \"./Results/Questions/Test questions different prompts/3-Filtered questions/Dev set\"\n",
    "filtered_questions_path_one_file = f\"./Results/Questions/Test questions different prompts/3-Filtered questions/Dev set/final_questions-{file_name}.json\"\n",
    "\n",
    "filtered_questions_path_SDGs = \"./Results/Questions/Test questions different prompts/4-Filtred questions with SDGs/Dev set/\"\n",
    "filtered_questions_path_SDGs_one_file = f\"./Results/Questions/Test questions different prompts/4-Filtred questions with SDGs/Dev set/final_questions-SDGs-{file_name}.json\"\n",
    "\n",
    "\n",
    "openaikey = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import json \n",
    "import openai\n",
    "import numpy as np \n",
    "def call_openai(prompt):\n",
    "\n",
    "\n",
    "    client = openai.OpenAI(api_key=openaikey)\n",
    "    # Ask GPT-4 for a brief overview\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric to remove the unrelevant questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_question(question, country):\n",
    "  relevance_prompt = f\"\"\"\n",
    "    You are an AI filter evaluating questions for a humanitarian situational report (SitRep) focused on {country}.\n",
    "  Analyze this question: \"{question}\" and evaluate the following criteria:\n",
    "\n",
    "  \n",
    "  1.  **Not Specific to {country}:** Does the question mention another place or country?\n",
    "  2.  **Too Political:**Does it focus heavily on political causes, express strong opinions, assign blame, propose political solutions or strategies, or exhibit bias instead of focusing on neutral humanitarian impact and response?\n",
    "  3.  **Long term/Historical:** Does the question focus on cumulative past events or speculative future scenarios, rather than immediate, actionable issues? Discard if it lacks clear relevance to the current humanitarian context or if it talks about a long term project. If there is a speicific period mentioned in the question it's likely that you should discard it. \n",
    "  4.  **Too general/too specific** Is it overly broad, abstract, or too specific? Even if the question is not related to the given country, it may still have a good generality level. \n",
    "  Each score should be evaluated indipendently from the others. \n",
    "  \n",
    "  Based strictly on these rules, respond with a JSON object in this format:\n",
    "    {{\n",
    "      \"score\": [0, 0, 0, 0],\n",
    "      \"reason\": [\"\", \"\", \"\", \"\"]\n",
    "    }}\n",
    "    \n",
    "  For the \"score\" array:\n",
    "  - Provide a 0 if the question meets the corresponding discard criterion.\n",
    "  - Provide a 1 if the question *does not* meet the corresponding discard criterion (meaning it's acceptable for that metric).\n",
    "\n",
    "  For the \"reason\" array:\n",
    "  - If a score for a criterion is 0, provide a brief explanation of why the question failed that specific criterion in the corresponding position in the \"reason\" array.\n",
    "  - If a score for a criterion is 1, leave the corresponding string in the \"reason\" array empty.\n",
    "    \"\"\"\n",
    "  #response = (call_google_gemini(relevance_prompt))\n",
    "  #response = call_google_gemini(relevance_prompt)\n",
    "  response= call_openai(relevance_prompt)\n",
    "  response = re.sub(r\"```(?:json)?\", \"\", response).strip().strip(\"`\")\n",
    "\n",
    "  try:\n",
    "      result = json.loads(response)\n",
    "      # Validate the structure of the score array if needed\n",
    "      if not isinstance(result.get(\"score\"), list) or len(result[\"score\"]) != 4:\n",
    "          print(f\"Warning: 'score' in JSON response is not a 4-element array: {result.get('score')}\")\n",
    "          # You might want to handle this as an error or try to default to something sensible\n",
    "          # For now, let's just return the potentially malformed result, or force a default\n",
    "          return {\"score\": [0, 0, 0, 0], \"reason\": \"Invalid 'score' array structure from AI response.\"}\n",
    "\n",
    "      return result\n",
    "  except json.JSONDecodeError as e:\n",
    "      print(\"JSON parse error:\", e)\n",
    "      # When parsing fails, return a default structure with all scores as 0\n",
    "      return {\"score\": [0, 0, 0, 0], \"reason\": \"Could not parse JSON structure from AI response.\"}\n",
    "\n",
    "\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering one file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(question_path_one_file, 'r') as file:\n",
    "    questions_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions = {}\n",
    "\n",
    "for key, item in questions_data.items():\n",
    "        fquestions = []\n",
    "        questions = item.get('picked_questions')\n",
    "        for question in questions:\n",
    "            question = question[2:]\n",
    "            print(question)\n",
    "            result = evaluate_question(question, country)\n",
    "            scores = result['score']\n",
    "            reasons = result['reason']\n",
    "            print(scores)\n",
    "            print(reasons)\n",
    "            \n",
    "            \n",
    "            if np.sum(scores) == 4: fquestions.append(question)\n",
    "            else: continue\n",
    "            \n",
    "        filtered_questions[key] = fquestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(filtered_questions_path_one_file, 'w') as f:\n",
    "    json.dump(filtered_questions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter questions in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import json\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from pathlib import Path \n",
    "\n",
    "\n",
    "\n",
    "# def process_files_in_folder(input_folder_path_str, output_folder_path_str):\n",
    "#     \"\"\"\n",
    "#     Processes all JSON files in the input folder, filters questions,\n",
    "#     and saves them to the output folder.\n",
    "#     \"\"\"\n",
    "#     input_folder = Path(input_folder_path_str)\n",
    "#     output_folder = Path(output_folder_path_str)\n",
    "#     print(input_folder)\n",
    "#     output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     for input_file_path in input_folder.glob('*.json'):\n",
    "#         file_name_with_extension = input_file_path.name\n",
    "#         file_name_stem = input_file_path.stem\n",
    "\n",
    "#         print(f\"\\n--- Processing file: {file_name_with_extension} ---\")\n",
    "\n",
    "#         try:\n",
    "#             country = file_name_stem.split('_')[0]\n",
    "#             if not country:\n",
    "#                 print(f\"Warning: Could not extract country from filename: {file_name_with_extension}. Skipping.\")\n",
    "#                 continue\n",
    "#         except IndexError:\n",
    "#             print(f\"Warning: Could not extract country from filename (no '_'): {file_name_with_extension}. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         print(f\"Extracted Country: {country}\")\n",
    "\n",
    "#         try:\n",
    "#             with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "#                 questions_data = json.load(file)\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(f\"Error: Could not decode JSON from {file_name_with_extension}. Skipping.\")\n",
    "#             continue\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error reading file {file_name_with_extension}: {e}. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         filtered_questions_for_file = {}\n",
    "#         for key, item in questions_data.items():\n",
    "#             fquestions = []\n",
    "#             questions_list = item.get('picked_questions')\n",
    "#             if not isinstance(questions_list, list):\n",
    "#                 continue\n",
    "\n",
    "#             for question_full_string in questions_list:\n",
    "#                 if not isinstance(question_full_string, str):\n",
    "#                     continue\n",
    "                \n",
    "#                 # --- MODIFIED LOGIC FOR QUESTION PROCESSING ---\n",
    "#                 question_processed = \"\" \n",
    "#                 if not question_full_string: # Handle empty string case\n",
    "#                     print(f\"\\nOriginal question string: '{question_full_string}'\")\n",
    "#                     print(f\"Warning: Original question string is empty. Skipping this question.\")\n",
    "#                     continue \n",
    "\n",
    "#                 if question_full_string[0].isalpha():\n",
    "#                     question_processed = question_full_string\n",
    "#                 else:\n",
    "#                     # If not a letter, remove the first two characters.\n",
    "#                     # Python's slice [2:] gracefully handles strings shorter than 2 chars by returning an empty string.\n",
    "#                     question_processed = question_full_string[2:]\n",
    "#                 # --- END OF MODIFIED LOGIC ---\n",
    "\n",
    "#                 print(f\"\\nOriginal question string: '{question_full_string}'\")\n",
    "#                 print(f\"Processed question: '{question_processed}'\")\n",
    "\n",
    "#                 # Evaluate the processed question\n",
    "#                 result = evaluate_question(question_processed, country)\n",
    "#                 scores = result.get('score')\n",
    "#                 reasons = result.get('reason', 'No reason provided.')\n",
    "\n",
    "#                 if scores is None or not isinstance(scores, list) or len(scores) != 4:\n",
    "#                     print(f\"Warning: Invalid scores format for question '{question_processed}'. Scores: {scores}. Skipping.\")\n",
    "#                     print(f\"Reason: {reasons}\")\n",
    "#                     continue\n",
    "                \n",
    "#                 print(f\"Scores: {scores}\")\n",
    "#                 print(f\"Reason: {reasons}\")\n",
    "\n",
    "#                 try:\n",
    "#                     if np.sum(scores) == 4:\n",
    "#                         fquestions.append(question_processed) # Storing the processed question\n",
    "#                         print(\"Question PASSED filter.\")\n",
    "#                     else:\n",
    "#                         print(\"Question FAILED filter.\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error during score summation or appending for question '{question_processed}': {e}\")\n",
    "#                     continue\n",
    "            \n",
    "#             if fquestions:\n",
    "#                 filtered_questions_for_file[key] = fquestions\n",
    "\n",
    "#         output_file_name = f\"final_questions-{file_name_stem}.json\"\n",
    "#         filtered_questions_path = output_folder / output_file_name\n",
    "\n",
    "#         if not filtered_questions_for_file:\n",
    "#             print(f\"No questions passed the filter for {file_name_with_extension}. Output file will be empty or not created if it doesn't contain any keys.\")\n",
    "        \n",
    "#         try:\n",
    "#             with open(filtered_questions_path, 'w', encoding='utf-8') as f:\n",
    "#                 json.dump(filtered_questions_for_file, f, indent=4)\n",
    "#             print(f\"Filtered questions saved to: {filtered_questions_path}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error writing output file {filtered_questions_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# process_files_in_folder(questions_path, filtered_questions_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDGs classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import filtered questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(filtered_questions_path_one_file, 'r') as f: \n",
    "    filtered_questions= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_descriptions = {\n",
    "    \"No Poverty\": \"Eradicate poverty in all its forms globally, with a focus on ensuring basic human needs such as food, shelter, and clean water, and increasing access to social protection and economic resources.\",\n",
    "    \"Zero Hunger\": \"End hunger and malnutrition by promoting sustainable agriculture, food security, improved nutrition, and equitable access to sufficient, nutritious food year-round.\",\n",
    "    \"Good Health and Well-being\": \"Ensure healthy lives and well-being for all by reducing maternal and child mortality, ending epidemics, improving healthcare systems, and ensuring universal access to health services.\",\n",
    "    \"Quality Education\": \"Provide inclusive, equitable, and high-quality education for all and promote lifelong learning opportunities to ensure literacy, numeracy, and access to skills for sustainable development.\",\n",
    "    \"Gender Equality\": \"Achieve gender equality by eliminating all forms of discrimination, violence, and harmful practices against women and girls, and empowering them through equal opportunities in leadership, education, and the workforce.\",\n",
    "    \"Clean Water and Sanitation\": \"Ensure universal access to clean water and adequate sanitation by improving water quality, managing water resources, reducing pollution, and promoting sustainable practices.\",\n",
    "    \"Affordable and Clean Energy\": \"Ensure universal access to affordable, reliable, and modern energy by increasing renewable energy production, improving energy efficiency, and promoting sustainable energy consumption.\",\n",
    "    \"Decent Work and Economic Growth\": \"Promote sustained, inclusive, and sustainable economic growth by providing productive employment, protecting labor rights, ensuring decent work conditions, and promoting economic equality.\",\n",
    "    \"Industry, Innovation, and Infrastructure\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization, and foster innovation to drive economic growth, technological progress, and sustainable development.\",\n",
    "    \"Reduced Inequality\": \"Reduce income inequality within and among countries by promoting social, economic, and political inclusion, as well as equal opportunities for marginalized and disadvantaged populations.\",\n",
    "    \"Sustainable Cities and Communities\": \"Make cities and human settlements inclusive, safe, resilient, and sustainable by ensuring affordable housing, reducing urban pollution, improving infrastructure, and promoting sustainable urban planning.\",\n",
    "    \"Responsible Consumption and Production\": \"Ensure sustainable consumption and production patterns by reducing waste, increasing recycling, promoting sustainable business practices, and encouraging responsible consumer behavior.\",\n",
    "    \"Climate Action\": \"Take urgent action to combat climate change and its impacts by reducing greenhouse gas emissions, building resilience to climate-related hazards, and integrating climate policies into national development strategies.\",\n",
    "    \"Life Below Water\": \"Conserve and sustainably use the oceans, seas, and marine resources by reducing marine pollution, protecting coastal ecosystems, and promoting sustainable fishing practices.\",\n",
    "    \"Life on Land\": \"Protect, restore, and promote sustainable use of terrestrial ecosystems, manage forests sustainably, combat desertification, halt biodiversity loss, and protect natural habitats.\",\n",
    "    \"Peace, Justice, and Strong Institutions\": \"Promote peaceful and inclusive societies by ensuring access to justice, reducing violence, building accountable institutions, and fostering good governance at all levels.\",\n",
    "    \"Partnerships for the Goals\": \"Strengthen global partnerships for sustainable development by mobilizing resources, sharing knowledge and technology, and promoting international cooperation for achieving the SDGs.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "def check_relevance_1sdg(question, sdg, description):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # CoT Prompt\n",
    "    prompt = (\n",
    "        f\"I need to analyze whether the following question is related to a specific Sustainable Development Goal (SDG).\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"SDG: {sdg}\\n\"\n",
    "        f\"Description: {description}\\n\\n\"\n",
    "        \"Your task is to determine if the question directly relates to this SDG. You can use your general knowledge, \"\n",
    "        \"along with the provided description, to compare the question to the SDG.\\n\\n\"\n",
    "        \"Please follow these steps:\\n\"\n",
    "        \"1. Identify key terms in the question.\\n\"\n",
    "        \"2. Consider how these terms relate to the SDG description.\\n\"\n",
    "        \"3. Based on your analysis, return only the following:\\n\"\n",
    "        \"   - Return '1' if the question is directly related to this SDG, or '0' if it is not.\\n\"\n",
    "        #\"   - The reasoning for your choice.\\n\"\n",
    "        \n",
    "        \"Provide your response in this format: \"\n",
    "        \" Score: \\n \"\n",
    "        \"Reason: \"\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Send the prompt to the LLM\n",
    "    client = OpenAI(api_key=\" \")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  \n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "   \n",
    "    \n",
    "        \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sdg_classification_prompt(question, sdgs_description_str):\n",
    "    prompt = f\"\"\"You are an expert in Sustainable Development Goals (SDGs).\n",
    "\n",
    "TASK OVERVIEW:\n",
    "Your job is to determine which SDGs are directly relevant to a given question. This classification will be used to group similar questions\n",
    "\n",
    "CLASSIFICATION CRITERIA:\n",
    "- Score 1: The question directly addresses, mentions, or requires knowledge about this specific SDG's core themes, targets, or indicators\n",
    "- Score 0: The question does not directly relate to this SDG, even if there might be indirect or tangential connections\n",
    "\n",
    "EVALUATION PROCESS:\n",
    "1. Read the question carefully\n",
    "2. For each of the 17 SDGs, independently assess whether the question directly relates to that SDG's primary focus areas\n",
    "3. Be precise - only mark as relevant (score 1) if there is a clear, direct connection\n",
    "4. Avoid marking SDGs as relevant based on weak or indirect associations\n",
    "\n",
    "QUESTION TO CLASSIFY:\n",
    "{question}\n",
    "\n",
    "SDG DESCRIPTIONS:\n",
    "{sdgs_description_str}\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return your response as a python array containing exactly 17 integers (0 or 1), where each position corresponds to SDGs 1-17 in order.\n",
    "\n",
    "Example:\n",
    "- If the question relates to SDG 1 (No Poverty) and SDG 8 (Decent Work), return: [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "- If the question relates only to SDG 3 (Good Health), return: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Your response must be only the python array, nothing else.\"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "def check_relevance_all_sdgs(question, sdgs_dict):\n",
    "    client = OpenAI(api_key=\"\")  # Ensure your API key is configured\n",
    "    \n",
    "    \n",
    "    sdgs_description_str = \"\"\n",
    "    for sdg_name, sdg_description in sdgs_dict.items():\n",
    "        sdgs_description_str += f\"- **{sdg_name}**: {sdg_description}\\n\"\n",
    "    \n",
    "    prompt = create_sdg_classification_prompt(question, sdgs_description_str)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Parse the Python array response\n",
    "    # Remove any potential backticks or code block markers\n",
    "    content = content.replace('```python', '').replace('```', '').strip()\n",
    "    \n",
    "    # Parse as Python literal (safer than eval)\n",
    "    import ast\n",
    "    parsed_results = ast.literal_eval(content)\n",
    "    \n",
    "    # Validate that we have exactly 17 scores\n",
    "    if len(parsed_results) != 17:\n",
    "        raise ValueError(f\"Expected 17 SDG scores, got {len(parsed_results)}\")\n",
    "    \n",
    "    # Validate that all scores are 0 or 1\n",
    "    for i, score in enumerate(parsed_results):\n",
    "        if score not in [0, 1]:\n",
    "            raise ValueError(f\"Invalid score {score} at position {i}. Scores must be 0 or 1.\")\n",
    "    \n",
    "    return parsed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_descriptions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "for key, questions in filtered_questions.items():\n",
    "    updated_questions = []\n",
    "    for q in questions: \n",
    "        result_q = check_relevance_all_sdgs(q, sdg_descriptions)\n",
    "        # Create the new dictionary structure for each question\n",
    "        question_data = {\n",
    "            'question': q,\n",
    "            'sdg_scores': result_q\n",
    "        }\n",
    "        updated_questions.append(question_data)\n",
    "    \n",
    "    # Replace the old list of strings with the new list of dictionaries\n",
    "    filtered_questions[key] = updated_questions\n",
    "        \n",
    "        \n",
    "# #            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file sdgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(filtered_questions_path_SDGs_one_file, 'w') as f:\n",
    "    json.dump(filtered_questions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDGs classificiation for folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "def classify_sdgs_in_folder(input_folder_path_str, output_folder_path_str):\n",
    "    \"\"\"\n",
    "    Processes all JSON files in the input folder, classify the sdgs,\n",
    "    and saves them to the output folder.\n",
    "    \"\"\"\n",
    "    input_folder = Path(input_folder_path_str)\n",
    "    output_folder = Path(output_folder_path_str)\n",
    "    print(input_folder)\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for input_file_path in input_folder.glob('*.json'):\n",
    "        file_name_with_extension = input_file_path.name\n",
    "        file_name_stem = input_file_path.stem\n",
    "\n",
    "        print(f\"\\n--- Processing file: {file_name_with_extension} ---\")\n",
    "\n",
    "        try:\n",
    "            country = file_name_stem.split('_')[0]\n",
    "            if not country:\n",
    "                print(f\"Warning: Could not extract country from filename: {file_name_with_extension}. Skipping.\")\n",
    "                continue\n",
    "        except IndexError:\n",
    "            print(f\"Warning: Could not extract country from filename (no '_'): {file_name_with_extension}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Extracted Country: {country}\")\n",
    "\n",
    "        try:\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "                filtered_questions = json.load(file)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Could not decode JSON from {file_name_with_extension}. Skipping.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_name_with_extension}: {e}. Skipping.\")\n",
    "            continue\n",
    "        file = filtered_questions.copy()\n",
    "        for key, questions in filtered_questions.items():\n",
    "            updated_questions = []\n",
    "            for q in questions: \n",
    "                result_q = check_relevance_all_sdgs(q, sdg_descriptions)\n",
    "                # Create the new dictionary structure for each question\n",
    "                question_data = {\n",
    "                    'question': q,\n",
    "                    'sdg_scores': result_q\n",
    "                }\n",
    "                updated_questions.append(question_data)\n",
    "            \n",
    "            # Replace the old list of strings with the new list of dictionaries\n",
    "            file[key] = updated_questions\n",
    "        \n",
    "        \n",
    "        output_file_name = f\"final_questions-SDGs-{file_name_stem}.json\"\n",
    "        filtered_questions_path = output_folder / output_file_name\n",
    "\n",
    "        try:\n",
    "            with open(filtered_questions_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(file, f, indent=4)\n",
    "            print(f\"Filtered questions saved to: {filtered_questions_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing output file {filtered_questions_path}: {e}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# classify_sdgs_in_folder(filtered_questions_path, filtered_questions_path_SDGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_timing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
