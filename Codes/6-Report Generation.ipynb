{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0604516",
   "metadata": {},
   "source": [
    "# Final Report Generation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook compiles the **final report** by combining all the results produced across the various folders.  \n",
    "In addition, **metadata** is added to each retrieved paragraph to ensure completeness and traceability.\n",
    "\n",
    "Two report formats are generated:\n",
    "1. A **Question–Answer (QA)** version.  \n",
    "2. A **summary-based** version organized by **sub-topic**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b99f72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_answers_data(answers_file):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw loaded JSON data to filter items that:\n",
    "    - Contain brackets (indicating citations)\n",
    "    - Do NOT contain 'no clear answer'\n",
    "\n",
    "    Args:\n",
    "        answers_file (list): The list of dictionaries loaded from the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries that meet the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_file = []\n",
    "    for item in answers_file:\n",
    "        answer = item.get('updated_answer_pt2', '')\n",
    "        \n",
    "        has_brackets = \"[\" in answer or \"]\" in answer\n",
    "        has_no_clear = re.search(r\"no clear answer\", answer, re.IGNORECASE)\n",
    "\n",
    "        if has_brackets and not has_no_clear:\n",
    "            filtered_file.append(item)\n",
    "\n",
    "    return filtered_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aff3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summary_data(summary_file):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw loaded JSON data to filter items with citations\n",
    "    and associate citations with their corresponding contexts.\n",
    "\n",
    "    Args:\n",
    "        answers_file (list): The list of dictionaries loaded from the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary has 'citations'\n",
    "              and 'used_contexts' keys added.\n",
    "    \"\"\"\n",
    "    \n",
    "    filtered_file = {}\n",
    "    for key, answer in summary_file.items():\n",
    "        # Only include items that potentially have citations\n",
    "        if \"[\" in answer or \"]\" in answer or re.search(r\"no clear answer[^\\w]*\", answer, re.IGNORECASE):\n",
    "            filtered_file[key] = answer\n",
    "    return filtered_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e2a8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_name(s):\n",
    "    \"\"\"\n",
    "    Parses a string in the format 'Country_event-period'\n",
    "    and returns a dictionary with keys: country, event, period.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        country_event, period = s.split(\"-\", 1)  # split only on first '-'\n",
    "        country, event = country_event.split(\"_\", 1)  # split only on first '_'\n",
    "        \n",
    "        return country,event,period\n",
    "    except ValueError:\n",
    "        raise ValueError(\"String does not match expected format: 'Country_event-period'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c86d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d78d2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1c14ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import random\n",
    "\n",
    "def enrich_contexts_with_citation_numbers(context_list, metadata_data, answer_text, similarity_threshold=0.7, min_substring_length=50):\n",
    "    \"\"\"\n",
    "    context_list: list of paragraph texts\n",
    "    metadata_data: list of dicts [{paragraph, title, url}, ...]\n",
    "    answer_text: the answer text containing citation numbers like [2][4]\n",
    "    similarity_threshold: minimum ratio (0–1) to accept fuzzy match\n",
    "    min_substring_length: minimum length for substring matching (avoids false positives)\n",
    "    Returns a dict keyed by citation numbers.\n",
    "    \"\"\"\n",
    "    # Extract citation numbers from the answer text\n",
    "    citation_numbers = np.unique(re.findall(r'\\[(\\d+)\\]', answer_text))\n",
    "    enriched_contexts = {}\n",
    "\n",
    "    # Pre-process metadata for faster lookups\n",
    "    # Create exact match lookup\n",
    "    exact_lookup = {item.get('paragraph', ''): item for item in metadata_data}\n",
    "    \n",
    "    # Create normalized substring lookup (only for substring matching)\n",
    "    substring_lookup = []\n",
    "    for item in metadata_data:\n",
    "        para = item.get('paragraph', '')\n",
    "        if para:\n",
    "            substring_lookup.append({\n",
    "                'normalized': para.lower().strip(),\n",
    "                'original': item\n",
    "            })\n",
    "\n",
    "    # Helper: get best fuzzy match (only called when needed)\n",
    "    def find_best_match(context_text):\n",
    "        best_match = None\n",
    "        best_ratio = 0.0\n",
    "        for item in metadata_data:\n",
    "            candidate_text = item.get('paragraph', '')\n",
    "            ratio = SequenceMatcher(None, context_text, candidate_text).ratio()\n",
    "            if ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_match = item\n",
    "        return best_match if best_ratio >= similarity_threshold else None\n",
    "\n",
    "    # Helper: find substring matches (optimized)\n",
    "    def find_substring_match(context_text):\n",
    "        \"\"\"\n",
    "        Check if context_text is contained within any metadata paragraph.\n",
    "        Returns first match found (or random if multiple).\n",
    "        \"\"\"\n",
    "        if len(context_text) < min_substring_length:\n",
    "            return None\n",
    "            \n",
    "        context_normalized = context_text.lower().strip()\n",
    "        matches = []\n",
    "        \n",
    "        # Simple substring search - much faster than fuzzy matching\n",
    "        for item in substring_lookup:\n",
    "            if context_normalized in item['normalized']:\n",
    "                matches.append(item['original'])\n",
    "                # Optionally break early if you only need one match\n",
    "                # break\n",
    "        \n",
    "        return random.choice(matches) if matches else None\n",
    "\n",
    "    # Step 1: Assign contexts to citations\n",
    "    for idx, citation in enumerate(citation_numbers):\n",
    "        if idx < len(context_list):\n",
    "            context_text = context_list[idx]\n",
    "            matched_metadata = None\n",
    "\n",
    "            # Try exact match first (O(1) lookup)\n",
    "            matched_metadata = exact_lookup.get(context_text)\n",
    "\n",
    "            # If no exact match, try substring matching (faster than fuzzy)\n",
    "            if not matched_metadata:\n",
    "                matched_metadata = find_substring_match(context_text)\n",
    "\n",
    "            # If still no match, try fuzzy whole-document match (slowest)\n",
    "            if not matched_metadata:\n",
    "                matched_metadata = find_best_match(context_text)\n",
    "\n",
    "            enriched_contexts[citation] = {\n",
    "                \"context\": context_text,\n",
    "                \"title\": matched_metadata.get(\"title\", \"\") if matched_metadata else \"\",\n",
    "                \"url\": matched_metadata.get(\"url\", \"\") if matched_metadata else \"\"\n",
    "            }\n",
    "        else:\n",
    "            # Step 2: No context available → still keep citation with placeholders\n",
    "            enriched_contexts[citation] = {\n",
    "                \"context\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "\n",
    "    return enriched_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ea617f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def enrich_summary_with_citation_numbers(summary_text, cited_paragraphs, metadata_data, similarity_threshold=0.7):\n",
    "    \"\"\"\n",
    "    summary_text: str, the summary string containing citations like [1][2]\n",
    "    cited_paragraphs: list of paragraph texts\n",
    "    metadata_data: list of dicts [{paragraph, title, url}, ...]\n",
    "    similarity_threshold: minimum similarity ratio (0–1) to accept fuzzy match\n",
    "    Returns a dict keyed by citation numbers.\n",
    "    \"\"\"\n",
    "    # Extract all citation numbers from the summary text\n",
    "    citation_numbers = np.unique(re.findall(r'\\[(\\d+)\\]', summary_text))\n",
    "    print(\"Summary citations found:\", citation_numbers)\n",
    "\n",
    "    enriched_contexts = {}\n",
    "\n",
    "    # Helper: find best fuzzy match\n",
    "    def find_best_match(context_text):\n",
    "        best_match = None\n",
    "        best_ratio = 0.0\n",
    "        for item in metadata_data:\n",
    "            candidate_text = item.get(\"paragraph\", \"\")\n",
    "            ratio = SequenceMatcher(None, context_text, candidate_text).ratio()\n",
    "            if ratio > best_ratio:\n",
    "                best_ratio = ratio\n",
    "                best_match = item\n",
    "        return best_match if best_ratio >= similarity_threshold else None\n",
    "\n",
    "    # Step 1: Assign contexts to citations\n",
    "    for idx, citation in enumerate(citation_numbers):\n",
    "        if idx < len(cited_paragraphs):\n",
    "            context_text = cited_paragraphs[idx]\n",
    "\n",
    "            # Try exact match first\n",
    "            matched_metadata = next(\n",
    "                (item for item in metadata_data if item.get(\"paragraph\", \"\") == context_text),\n",
    "                None\n",
    "            )\n",
    "\n",
    "            # If no exact match, try fuzzy matching\n",
    "            if not matched_metadata:\n",
    "                matched_metadata = find_best_match(context_text)\n",
    "\n",
    "            enriched_contexts[citation] = {\n",
    "                \"context\": context_text,\n",
    "                \"title\": matched_metadata.get(\"title\", \"\") if matched_metadata else \"\",\n",
    "                \"url\": matched_metadata.get(\"url\", \"\") if matched_metadata else \"\"\n",
    "            }\n",
    "        else:\n",
    "            # No paragraph for this citation\n",
    "            enriched_contexts[citation] = {\n",
    "                \"context\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "\n",
    "    return enriched_contexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceda1be",
   "metadata": {},
   "source": [
    "# Create reports with QA + Citations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d0600af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Names: ['Afghanistan_Afghanistan Floods-Week 21 2024', 'Bangladesh_Cyclone Remal-Week 21 2024', 'Haiti_Gang violence and humanitarian crisis in Haiti-Week 40 2024', 'India_LandslideFloods-Week 31 2024', 'Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024', 'Israel_Israel-Hamas war-Week 19 2024', 'Israel_Israel_Palestine_confilct-Week 40 2024', 'Jamaica_Hurricane Beryl-Week 28 2024', 'Nigeria_Flooding in Nigeria-Week 37 2024', 'Pakistan_Monsoon floods and rains in Pakistan-Week 31 2024', 'Sudan_Sudan conflict-Week 34 2024', 'Sudan_Sudan conflict-Week 39 2024', 'Ukraine_Ukraine-Week 23 2024', 'United Kingdom_UK riots-Week 32 2024']\n",
      "\n",
      "answers_new_cit-answes-Afghanistan_Afghanistan Floods-Week 21 2024-prompt-1.json -> original: 30, filtered: 28, removed: 2\n",
      "Summary citations found: ['17' '32' '39' '46' '64' '7']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Afghanistan_Afghanistan Floods-Week 21 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Afghanistan_Afghanistan Floods-Week 21 2024.md\n",
      "answers_new_cit-answes-Bangladesh_Cyclone Remal-Week 21 2024-prompt-1.json -> original: 44, filtered: 31, removed: 13\n",
      "Summary citations found: ['11' '34' '48' '63' '67' '70' '72' '73' '74' '77']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Bangladesh_Cyclone Remal-Week 21 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Bangladesh_Cyclone Remal-Week 21 2024.md\n",
      "answers_new_cit-answes-Haiti_Gang violence and humanitarian crisis in Haiti-Week 40 2024-prompt-1.json -> original: 79, filtered: 65, removed: 14\n",
      "Summary citations found: ['124' '129' '135' '136' '138' '139' '142' '3' '41' '63' '75']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Haiti_Gang violence and humanitarian crisis in Haiti-Week 40 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Haiti_Gang violence and humanitarian crisis in Haiti-Week 40 2024.md\n",
      "answers_new_cit-answes-India_LandslideFloods-Week 31 2024-prompt-1.json -> original: 56, filtered: 41, removed: 15\n",
      "Summary citations found: ['1' '34' '42' '49' '52' '57' '69' '92']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/India_LandslideFloods-Week 31 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/India_LandslideFloods-Week 31 2024.md\n",
      "answers_new_cit-answes-Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024-prompt-1.json -> original: 26, filtered: 19, removed: 7\n",
      "Summary citations found: ['11' '12' '20' '21' '22' '23' '24' '7']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024.md\n",
      "answers_new_cit-answes-Israel_Israel-Hamas war-Week 19 2024-prompt-1.json -> original: 13, filtered: 13, removed: 0\n",
      "Summary citations found: ['12' '17' '19' '27' '30' '7']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Israel_Israel-Hamas war-Week 19 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Israel_Israel-Hamas war-Week 19 2024.md\n",
      "answers_new_cit-answes-Israel_Israel_Palestine_confilct-Week 40 2024-prompt-1.json -> original: 31, filtered: 29, removed: 2\n",
      "Summary citations found: ['50' '55' '6' '73' '81' '98']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Israel_Israel_Palestine_confilct-Week 40 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Israel_Israel_Palestine_confilct-Week 40 2024.md\n",
      "answers_new_cit-answes-Jamaica_Hurricane Beryl-Week 28 2024-prompt-1.json -> original: 36, filtered: 34, removed: 2\n",
      "Summary citations found: ['20' '25' '32' '36' '43' '54' '62']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Jamaica_Hurricane Beryl-Week 28 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Jamaica_Hurricane Beryl-Week 28 2024.md\n",
      "answers_new_cit-answes-Nigeria_Flooding in Nigeria-Week 37 2024-prompt-1.json -> original: 27, filtered: 24, removed: 3\n",
      "Summary citations found: ['1' '18' '46' '52' '72' '75' '9']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Nigeria_Flooding in Nigeria-Week 37 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Nigeria_Flooding in Nigeria-Week 37 2024.md\n",
      "answers_new_cit-answes-Pakistan_Monsoon floods and rains in Pakistan-Week 31 2024-prompt-1.json -> original: 15, filtered: 10, removed: 5\n",
      "Summary citations found: ['10' '13' '14' '15' '17' '18' '25']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Pakistan_Monsoon floods and rains in Pakistan-Week 31 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Pakistan_Monsoon floods and rains in Pakistan-Week 31 2024.md\n",
      "answers_new_cit-answes-Sudan_Sudan conflict-Week 34 2024-prompt-1.json -> original: 19, filtered: 17, removed: 2\n",
      "Summary citations found: ['1' '19' '30' '31' '39' '40' '43' '45' '7' '8']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Sudan_Sudan conflict-Week 34 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Sudan_Sudan conflict-Week 34 2024.md\n",
      "Cluster summaries file not found for Sudan_Sudan conflict-Week 39 2024: ./Results/Summaries/UniqueSummary-EachCluster/Dev set/summary_Sudan_Sudan conflict-Week 39 2024.json\n",
      "QA file not found for Sudan_Sudan conflict-Week 39 2024: ./Results/Answers/Answers-subtopics/Dev set/Updated_citations/answers_new_cit-answes-Sudan_Sudan conflict-Week 39 2024-prompt-1.json\n",
      "Metadata file not found for Sudan_Sudan conflict-Week 39 2024: metadata-sources-metadata-Sudan_Sudan conflict-Week 39 2024.json\n",
      "Summary file not found for Sudan_Sudan conflict-Week 39 2024: ./Results/Executive Summaries/Dev set/Updated_citations/summary-Sudan_Sudan conflict-Week 39 2024.json\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Sudan_Sudan conflict-Week 39 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Sudan_Sudan conflict-Week 39 2024.md\n",
      "answers_new_cit-answes-Ukraine_Ukraine-Week 23 2024-prompt-1.json -> original: 55, filtered: 48, removed: 7\n",
      "Summary citations found: ['28' '46' '49' '5' '79' '83' '87' '89' '90' '92']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/Ukraine_Ukraine-Week 23 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/Ukraine_Ukraine-Week 23 2024.md\n",
      "answers_new_cit-answes-United Kingdom_UK riots-Week 32 2024-prompt-1.json -> original: 23, filtered: 22, removed: 1\n",
      "Summary citations found: ['26' '37' '59' '68' '75' '80' '88']\n",
      "Created combined data file: ./Results/Reports/JSON_Report_QA/Dev set/United Kingdom_UK riots-Week 32 2024_combined_data.json\n",
      "Created Markdown file: ./Results/Reports/Markdown_Report_QA/Dev set/United Kingdom_UK riots-Week 32 2024.md\n",
      "\n",
      "--- Processing Complete ---\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "devOrTest = \"Dev\"\n",
    "# Define your source and cluster folders using f-strings\n",
    "sources_folder = f\"./Results/Sources/SourcesCountryEvent/{devOrTest} set/\"\n",
    "clusters_folder = \"./Results/Cluster/Clusters+Headline \"\n",
    "qa_folder = f\"./Results/Answers/Answers-subtopics/Dev set/Updated_citations\"\n",
    "metadata_folder = \"./Results/paragraphs_metadata\"\n",
    "summary_folder = f\"./Results/Executive Summaries/Dev set/Updated_citations\"\n",
    "cluster_summaries_folder = f\"./Results/Summaries/UniqueSummary-EachCluster/{devOrTest} set\"\n",
    "output_folder = f\"./Results/Reports/JSON_Report_QA/{devOrTest} set\"\n",
    "markdown_output_folder = f\"./Results/Reports/Markdown_Report_QA/{devOrTest} set\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "os.makedirs(markdown_output_folder, exist_ok=True)\n",
    "\n",
    "# Get all JSON file names from the sources folder, sorted\n",
    "json_files = np.sort([f for f in os.listdir(sources_folder) if f.endswith('.json')])\n",
    "base_names = [os.path.splitext(f)[0] for f in json_files]\n",
    "print(f\"Base Names: {base_names}\\n\")\n",
    "\n",
    "for json_file in json_files:\n",
    "    base_name = os.path.splitext(json_file)[0]\n",
    "\n",
    "    # Load cluster data\n",
    "    cluster_name = f\"clusters-{base_name}.json\"\n",
    "    data_clusters = {}\n",
    "    try:\n",
    "        with open(os.path.join(clusters_folder, cluster_name), 'r') as file:\n",
    "            data_clusters = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Cluster file not found for {base_name}: {os.path.join(clusters_folder, cluster_name)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Problems reading cluster file {os.path.join(clusters_folder, cluster_name)}: {e}\")\n",
    "\n",
    "    # Load cluster summaries with titles\n",
    "    cluster_summary_name = f\"summary_{base_name}.json\"\n",
    "    cluster_summaries = {}\n",
    "    try:\n",
    "        with open(os.path.join(cluster_summaries_folder, cluster_summary_name), 'r') as file:\n",
    "            cluster_summaries = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Cluster summaries file not found for {base_name}: {os.path.join(cluster_summaries_folder, cluster_summary_name)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Problems reading cluster summaries file {os.path.join(cluster_summaries_folder, cluster_summary_name)}: {e}\")\n",
    "\n",
    "    # Load QA data\n",
    "    qa_name = f\"answers_new_cit-answes-{base_name}-prompt-1.json\"\n",
    "    data_qa = []\n",
    "    try:\n",
    "        with open(os.path.join(qa_folder, qa_name), 'r') as file:\n",
    "            data_qa = json.load(file)\n",
    "            before = len(data_qa)\n",
    "\n",
    "            data_qa = preprocess_answers_data(data_qa)\n",
    "            after = len(data_qa)\n",
    "\n",
    "            print(f\"{qa_name} -> original: {before}, filtered: {after}, removed: {before - after}\")\n",
    "            \n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"QA file not found for {base_name}: {os.path.join(qa_folder, qa_name)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Problems reading QA file {os.path.join(qa_folder, qa_name)}: {e}\")\n",
    "\n",
    "    # Load Metadata Data\n",
    "    metadata_file_name = f\"metadata-sources-metadata-{base_name}.json\"\n",
    "    metadata_data = []\n",
    "    try:\n",
    "        with open(os.path.join(metadata_folder, metadata_file_name), 'r', encoding='utf-8') as file:\n",
    "            metadata_data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Metadata file not found for {base_name}: {metadata_file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Problems reading metadata file {metadata_file_name}: {e}\")\n",
    "\n",
    "    # --- Create the combined JSON structure ---\n",
    "    output_data = {'file_name': base_name}\n",
    "    \n",
    "    ## 1. Get summary\n",
    "    summary_file_name = f\"summary-{base_name}.json\"\n",
    "    try:\n",
    "        with open(os.path.join(summary_folder, summary_file_name), 'r') as file:\n",
    "            data_summary = json.load(file)\n",
    "            summary_text = data_summary.get('new_summary', '')\n",
    "            cited_paragraphs = data_summary.get('new_cited_paragraphs', [])\n",
    "\n",
    "            output_data['summary'] = summary_text\n",
    "            output_data['summary_contexts'] = enrich_summary_with_citation_numbers(\n",
    "                summary_text, cited_paragraphs, metadata_data\n",
    "            )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Summary file not found for {base_name}: {os.path.join(summary_folder, summary_file_name)}\")\n",
    "        output_data['summary'] = \"\"\n",
    "        output_data['summary_contexts'] = {}\n",
    "    except Exception as e:\n",
    "        print(f\"Problems reading summary file {os.path.join(summary_folder, summary_file_name)}: {e}\")\n",
    "        output_data['summary'] = \"\"\n",
    "        output_data['summary_contexts'] = {}\n",
    "\n",
    "    # 2. Organize QA by cluster_id\n",
    "    qa_by_cluster = {}\n",
    "    for qa_item in data_qa:\n",
    "        cluster_id = qa_item.get('cluster_id')\n",
    "        if cluster_id:\n",
    "            if cluster_id not in qa_by_cluster:\n",
    "                qa_by_cluster[cluster_id] = []\n",
    "            original_context = qa_item.get('new_used_contexts', [])\n",
    "            answer_text = qa_item.get('updated_answer_pt2', '')\n",
    "            enriched_context = enrich_contexts_with_citation_numbers(original_context, metadata_data, answer_text)\n",
    "\n",
    "            qa_by_cluster[cluster_id].append({\n",
    "                'question': qa_item.get('question', ''),\n",
    "                'updated_retrieved_answer': answer_text,\n",
    "                'used_contexts': enriched_context\n",
    "            })\n",
    "\n",
    "    # 3. Process clusters\n",
    "    output_data['clusters'] = []\n",
    "    if isinstance(data_clusters, dict):\n",
    "        for cluster_id, cluster_info in data_clusters.items():\n",
    "            qa_items = qa_by_cluster.get(cluster_id, [])\n",
    "            if qa_items:  # ✅ only keep clusters with at least one QA\n",
    "                # Get title from cluster summaries\n",
    "                cluster_title = cluster_summaries.get(cluster_id, {}).get('title', cluster_info.get('cluster_headline', ''))\n",
    "                \n",
    "                cluster_entry = {\n",
    "                    'cluster_id': cluster_id,\n",
    "                    'cluster_headline': cluster_title,\n",
    "                    'questions_and_answers': qa_items\n",
    "                }\n",
    "                output_data['clusters'].append(cluster_entry)\n",
    "    else:\n",
    "        print(f\"Warning: data_clusters for {base_name} is not a dictionary. Skipping cluster processing.\")\n",
    "\n",
    "    # Save combined JSON\n",
    "    output_file_path = os.path.join(output_folder, f\"{base_name}_combined_data.json\")\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(output_data, outfile, indent=4, ensure_ascii=False)\n",
    "    print(f\"Created combined data file: {output_file_path}\")\n",
    "\n",
    "    # --- Generate Markdown ---\n",
    "    country, event, period = parse_file_name(output_data['file_name'])\n",
    "    markdown_content = f\"# {event} {period}\\n\\n\"\n",
    "    markdown_content += \"## Summary \\n\"\n",
    "    markdown_content += f\"{output_data['summary']}\\n\\n\"\n",
    "    markdown_content += \"## Questions and Answers\\n\\n\"\n",
    "\n",
    "    for cluster in output_data['clusters']:\n",
    "        if cluster['questions_and_answers']:\n",
    "            markdown_content += f\"### {cluster['cluster_headline']}\\n\\n\"\n",
    "            for qa in cluster['questions_and_answers']:\n",
    "                markdown_content += f\"**Question:** {qa['question']}\\n\"\n",
    "                markdown_content += f\"**Answer:** {qa['updated_retrieved_answer']}\\n\\n\"\n",
    "\n",
    "    markdown_file_path = os.path.join(markdown_output_folder, f\"{base_name}.md\")\n",
    "    with open(markdown_file_path, 'w', encoding='utf-8') as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "    print(f\"Created Markdown file: {markdown_file_path}\")\n",
    "\n",
    "print(\"\\n--- Processing Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836401e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f577fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3bfd9b7",
   "metadata": {},
   "source": [
    "# Create report just with the summary in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37cf309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def enrich_contexts(used_contexts, metadata_data, min_substring_length=50):\n",
    "    \"\"\"\n",
    "    used_contexts: dict {id: paragraph_text}\n",
    "    metadata_data: list of dicts [{paragraph, title, url}, ...]\n",
    "    min_substring_length: minimum length for substring matching\n",
    "    \"\"\"\n",
    "    # Pre-process metadata for faster lookups\n",
    "    # Create exact match lookup (O(1))\n",
    "    exact_lookup = {item.get('paragraph', ''): item for item in metadata_data}\n",
    "    \n",
    "    # Create normalized substring lookup\n",
    "    substring_lookup = []\n",
    "    for item in metadata_data:\n",
    "        para = item.get('paragraph', '')\n",
    "        if para:\n",
    "            substring_lookup.append({\n",
    "                'normalized': para.lower().strip(),\n",
    "                'original': item\n",
    "            })\n",
    "    \n",
    "    # Helper: find substring match\n",
    "    def find_substring_match(context_text):\n",
    "        if len(context_text) < min_substring_length:\n",
    "            return None\n",
    "            \n",
    "        context_normalized = context_text.lower().strip()\n",
    "        matches = []\n",
    "        \n",
    "        for item in substring_lookup:\n",
    "            if context_normalized in item['normalized']:\n",
    "                matches.append(item['original'])\n",
    "        \n",
    "        return random.choice(matches) if matches else None\n",
    "    \n",
    "    enriched = {}\n",
    "    for cid, context_text in used_contexts.items():\n",
    "        matched_metadata = None\n",
    "        \n",
    "        # Try exact match first (O(1))\n",
    "        matched_metadata = exact_lookup.get(context_text)\n",
    "        \n",
    "        # If no exact match, try substring matching\n",
    "        if not matched_metadata:\n",
    "            matched_metadata = find_substring_match(context_text)\n",
    "        \n",
    "        if matched_metadata:\n",
    "            enriched[cid] = {\n",
    "                \"context\": context_text,\n",
    "                \"title\": matched_metadata.get(\"title\", \"\"),\n",
    "                \"url\": matched_metadata.get(\"url\", \"\")\n",
    "            }\n",
    "        else:\n",
    "            enriched[cid] = {\n",
    "                \"context\": context_text,\n",
    "                \"title\": \"\",\n",
    "                \"url\": \"\"\n",
    "            }\n",
    "    \n",
    "    return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f01e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_timing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
