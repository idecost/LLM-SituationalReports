{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b402b7",
   "metadata": {},
   "source": [
    "# Post-processing of Executive Summary Citations\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs the **post-processing** of the citations contained in the **executive summaries** generated in the previous step.  \n",
    "The goal is to refine, standardize, and ensure the consistency of citation formatting.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "At the beginning of the notebook, update the **path variables** to specify the input and output directories used throughout the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "input_path = f'./Results/Executive Summary/Dev set'\n",
    "output_path = os.path.join(input_path, \"Updated_citations\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    \"\"\"Compute Jaccard similarity between two texts (set of words).\"\"\"\n",
    "    set1, set2 = set(text1.lower().split()), set(text2.lower().split())\n",
    "    if not set1 or not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "def update_citations_in_file(\n",
    "    file_data,\n",
    "    mu=0.8,\n",
    "    threshold=0.3,\n",
    "    model_name='nomic-ai/modernbert-embed-base'\n",
    "):\n",
    "    \"\"\"\n",
    "    Update citations in a file with structure:\n",
    "    {\n",
    "      \"summary\": \"...\",\n",
    "      \"cited_paragraphs\": [...],\n",
    "      \"full_paragraphs\": [...]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        model = SentenceTransformer(model_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SentenceTransformer model '{model_name}': {e}\")\n",
    "        return file_data  # Return unchanged if model fails\n",
    "\n",
    "    summary = file_data.get(\"summary\", \"\")\n",
    "    retrieved_docs = file_data.get(\"full_paragraphs\", [])\n",
    "\n",
    "    if not summary or not retrieved_docs:\n",
    "        file_data[\"new_summary\"] = summary\n",
    "        file_data[\"new_citations\"] = []\n",
    "        file_data[\"new_cited_paragraphs\"] = []\n",
    "        return file_data\n",
    "\n",
    "    \n",
    "    pattern = re.compile(r\"(.*?)((\\[\\d+\\])+)\", re.DOTALL)\n",
    "    matches = list(pattern.finditer(summary))\n",
    "\n",
    "    \n",
    "    query_embedding = model.encode([summary])\n",
    "\n",
    "    \n",
    "    cosine_scores = np.array([])\n",
    "    if retrieved_docs:\n",
    "        doc_embeddings = model.encode(retrieved_docs)\n",
    "        if doc_embeddings.ndim == 2 and doc_embeddings.shape[0] > 0:\n",
    "            cosine_scores = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "\n",
    "    updated_summary = summary\n",
    "    current_offset = 0\n",
    "    all_new_indices = set()\n",
    "\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            text_piece = match.group(1).strip()\n",
    "            original_citation_str = match.group(2)\n",
    "            original_indices = [int(num) for num in re.findall(r'\\d+', original_citation_str)]\n",
    "            k = len(original_indices)\n",
    "\n",
    "            new_indices = []\n",
    "            new_marker_str = \"\"\n",
    "\n",
    "            if k > 0 and retrieved_docs and cosine_scores.size > 0:\n",
    "                piece_scores = []\n",
    "                for j, doc_text in enumerate(retrieved_docs):\n",
    "                    jac = jaccard_similarity(text_piece, doc_text)\n",
    "                    cos = cosine_scores[j]\n",
    "                    combined = mu * jac + (1 - mu) * cos\n",
    "                    piece_scores.append((combined, j + 1))  # 1-based index\n",
    "\n",
    "                piece_scores.sort(reverse=True, key=lambda x: x[0])\n",
    "                top_k = piece_scores[:k]\n",
    "\n",
    "                new_indices = [doc_idx for score, doc_idx in top_k if score >= threshold]\n",
    "                if not new_indices and top_k:\n",
    "                    new_indices = [top_k[0][1]]\n",
    "\n",
    "                new_indices.sort()\n",
    "                new_marker_str = ''.join([f'[{i}]' for i in new_indices])\n",
    "\n",
    "            \n",
    "            for idx in new_indices:\n",
    "                all_new_indices.add(idx)\n",
    "\n",
    "            replacement = text_piece + new_marker_str\n",
    "            start, end = match.start(), match.end()\n",
    "            updated_summary = (\n",
    "                updated_summary[:start + current_offset] +\n",
    "                replacement +\n",
    "                updated_summary[end + current_offset:]\n",
    "            )\n",
    "            current_offset += len(replacement) - (end - start)\n",
    "\n",
    "    # Save results back\n",
    "    file_data[\"new_summary\"] = updated_summary\n",
    "    file_data[\"new_citations\"] = sorted(list(all_new_indices))\n",
    "    file_data[\"new_cited_paragraphs\"] = [\n",
    "        retrieved_docs[i - 1] for i in file_data[\"new_citations\"]\n",
    "        if 0 < i <= len(retrieved_docs)\n",
    "    ]\n",
    "\n",
    "    return file_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606dbcb",
   "metadata": {},
   "source": [
    "# Process all the files in a folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eff1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Loop through all JSON files in the directory\n",
    "for fname in os.listdir(input_path):\n",
    "    if not fname.endswith(\".json\"):\n",
    "        continue\n",
    "\n",
    "    fpath = os.path.join(input_path, fname)\n",
    "    try:\n",
    "        with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {fname} (error reading JSON: {e})\")\n",
    "        continue\n",
    "\n",
    "    # Update citations\n",
    "    updated_data = update_citations_in_file(file_data)\n",
    "\n",
    "    # Save output JSON\n",
    "    out_fpath = os.path.join(output_path, fname)\n",
    "    try:\n",
    "        with open(out_fpath, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(updated_data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"✅ Processed and saved: {out_fpath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not save {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730509b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_timing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
