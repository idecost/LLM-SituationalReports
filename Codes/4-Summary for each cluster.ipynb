{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515bf0ed",
   "metadata": {},
   "source": [
    "# Cluster Citation Post-processing and Question Summarization\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs two main tasks:\n",
    "\n",
    "1. **Post-processing of citations** for each cluster, assigning **unique values** to each answer (e.g., 1–10 for the first cluster, 11–20 for the second, etc.).\n",
    "2. **Summarization of questions** associated with each **sub-topic**, providing concise overviews of the clustered content.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "At the beginning of the notebook, update the **path variables** to specify the input data, output directories, and any other required resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "\n",
    "input_path = \"./Results/Answers/Answers-subtopics/Dev set/Updated_citations\"\n",
    "output_path = \"./Results/Summaries/UniqueSummary-EachCluster/Dev set\"\n",
    "\n",
    "\n",
    "\n",
    "openaikey = \"\"\n",
    "json_files = np.sort([f for f in os.listdir(input_path) if f.endswith('.json')])\n",
    "\n",
    "file = json_files[2]\n",
    "file_name = file.replace('answers_new_cit-answes-', '').replace('-prompt-1.json', '')\n",
    "\n",
    "with open(os.path.join(input_path, file), 'r') as f:\n",
    "    json_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fc04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_answers = []\n",
    "    \n",
    "# Group answers by cluster_id to process them in order\n",
    "clusters = {}\n",
    "for item in json_data:\n",
    "    cluster_id = item.get('cluster_id')\n",
    "    retrieved_answer = item.get('updated_retrieved_answer')\n",
    "    if cluster_id and retrieved_answer is not None:\n",
    "        if cluster_id not in clusters:\n",
    "            clusters[cluster_id] = []\n",
    "        clusters[cluster_id].append(retrieved_answer)\n",
    "\n",
    "# Process each cluster\n",
    "modified_answers = {}\n",
    "for cluster_id in clusters.keys(): # Sort to ensure consistent order\n",
    "    answers_in_cluster = clusters[cluster_id]\n",
    "    \n",
    "    modified_answers[cluster_id] = [] \n",
    "    for i, original_answer in enumerate(answers_in_cluster):\n",
    "        \n",
    "        offset = i * 10\n",
    "\n",
    "        modified_answer = original_answer\n",
    "\n",
    "        \n",
    "        citations_found = set(re.findall(r'\\[(\\d+)\\]', original_answer))\n",
    "\n",
    "        \n",
    "        sorted_citations = sorted([int(c) for c in citations_found], reverse=True)\n",
    "\n",
    "        for old_citation_num in sorted_citations:\n",
    "            new_citation_num = old_citation_num + offset\n",
    "           \n",
    "            modified_answer = re.sub(\n",
    "                r'\\[{}\\]'.format(re.escape(str(old_citation_num))),\n",
    "                '[{}]'.format(new_citation_num),\n",
    "                modified_answer\n",
    "            )\n",
    "\n",
    "        modified_answers[cluster_id].append(modified_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openaikey) \n",
    "\n",
    "# Dictionary to store the summaries\n",
    "summarized_answers = {}\n",
    "prompt = \"\"\"\n",
    "Your task is to integrate the following pieces of text into a single, cohesive, and flowing narrative. The goal is to present as much of the original information as possible, not to summarize it briefly.\n",
    "\n",
    "The text contains information with citations, formatted as `[number]`. It is crucial that you adhere to the following rules:\n",
    "\n",
    "1.  **Integrate all key information**: Combine sentences and ideas from the input to form a comprehensive and coherent text. Aim to include a good portion, if not all, of the provided details.\n",
    "2.  **Maintain original citations**: Every piece of information you include in the integrated text must retain its original citation(s).\n",
    "3.  **Handle citations when combining**: If you rephrase or combine sentences containing information from multiple sources, ensure that *all* relevant original citation numbers for that combined information are included at the end of the new sentence. For example, if a new sentence merges details from original sentences cited `[1]` and `[5]`, the new sentence should be followed by `[1][5]`.\n",
    "4.  **Ensure logical flow**: Arrange the information in a way that creates a natural and readable progression of ideas, even if it means reordering content from the original input.\n",
    "5.  **Avoid external knowledge**: Your output must be based *solely* on the information provided in the input text. Do not introduce any outside facts or personal opinions.\n",
    "\n",
    "Here is the text to integrate:\n",
    "{text_to_integrate}\n",
    "\"\"\"\n",
    "\n",
    "# Iterate through each cluster and its modified answers\n",
    "for cluster_id, answers in modified_answers.items():\n",
    "    \n",
    "    text_to_summarize = \"\\n\\n\".join(answers)\n",
    "    custom_prompt = prompt.format(text_to_integrate = text_to_summarize)\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", # Specify the GPT-4o model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in combining text.\"},\n",
    "                {\"role\": \"user\", \"content\": custom_prompt}\n",
    "            ],\n",
    "            \n",
    "            temperature=0.0\n",
    "        )\n",
    "        summary = response.choices[0].message.content.strip()\n",
    "        summarized_answers[cluster_id] = summary\n",
    "        print(f\"Summary for {cluster_id}:\\n{summary}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while summarizing cluster {cluster_id}: {e}\")\n",
    "        summarized_answers[cluster_id] = f\"Error: Could not summarize due to {e}\"\n",
    "\n",
    "\n",
    "print(\"\\n--- All Summaries ---\")\n",
    "print(json.dumps(summarized_answers, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(summarized_answers['0'], width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6146c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_answers['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730feb9",
   "metadata": {},
   "source": [
    "# Perform summarization of each cluster in each file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openaikey)\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Your task is to integrate the following pieces of text into a single, cohesive, and flowing narrative. The goal is to present as much of the original information as possible, not to summarize it briefly.\n",
    "\n",
    "The text contains information with citations, formatted as `[number]`. It is crucial that you adhere to the following rules:\n",
    "\n",
    "1.  **Integrate all key information**: Combine sentences and ideas from the input to form a comprehensive and coherent text. Aim to include a good portion, if not all, of the provided details.\n",
    "2.  **Maintain original citations**: Every piece of information you include in the integrated text must retain its original citation(s).\n",
    "3.  **Handle citations when combining**: If you rephrase or combine sentences containing information from multiple sources, ensure that *all* relevant original citation numbers for that combined information are included at the end of the new sentence. For example, if a new sentence merges details from original sentences cited `[1]` and `[5]`, the new sentence should be followed by `[1][5]`.\n",
    "4.  **Ensure logical flow**: Arrange the information in a way that creates a natural and readable progression of ideas, even if it means reordering content from the original input.\n",
    "5.  **Avoid external knowledge**: Your output must be based *solely* on the information provided in the input text. Do not introduce any outside facts or personal opinions.\n",
    "\n",
    "Here is the text to integrate:\n",
    "{text_to_integrate}\n",
    "\"\"\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    json_files = np.sort([f for f in os.listdir(input_path) if f.endswith('.json')])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The directory '{input_path}' was not found.\")\n",
    "    json_files = []\n",
    "\n",
    "# --- Process each file ---\n",
    "for file in json_files:\n",
    "    file_name = file.replace('answers_new_cit-answes-', '').replace('-prompt-1.json', '')\n",
    "    \n",
    "    # Check if output file already exists\n",
    "    output_filename = os.path.join(output_path, f\"summary_{file_name}.json\")\n",
    "    if os.path.exists(output_filename):\n",
    "        print(f\"--- Skipping file: {file_name} (output already exists) ---\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"--- Processing file: {file_name} ---\")\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(input_path, file), 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from file: {file}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading {file}: {e}\")\n",
    "        continue\n",
    "\n",
    " \n",
    "    clusters = {}\n",
    "    for item in json_data:\n",
    "        cluster_id = item.get('cluster_id')\n",
    "        retrieved_answer = item.get('updated_retrieved_answer')\n",
    "        if cluster_id and retrieved_answer is not None:\n",
    "            clusters.setdefault(cluster_id, []).append(item)\n",
    "\n",
    "    \n",
    "    modified_answers = {}\n",
    "    updated_citation_contexts = {}\n",
    "\n",
    "    for cluster_id in sorted(clusters.keys()):\n",
    "        modified_answers[cluster_id] = []\n",
    "        updated_citation_contexts[cluster_id] = {}\n",
    "\n",
    "        for i, item in enumerate(clusters[cluster_id]):\n",
    "            original_answer = item['updated_retrieved_answer']\n",
    "            offset = i * 10\n",
    "            modified_answer = original_answer\n",
    "\n",
    "            citations_found = set(re.findall(r'\\[(\\d+)\\]', original_answer))\n",
    "            sorted_citations = sorted([int(c) for c in citations_found], reverse=True)\n",
    "\n",
    "            for old_citation_num in sorted_citations:\n",
    "                new_citation_num = old_citation_num + offset\n",
    "                # Replace citation in text\n",
    "                modified_answer = re.sub(\n",
    "                    r'\\[{}\\]'.format(re.escape(str(old_citation_num))),\n",
    "                    '[{}]'.format(new_citation_num),\n",
    "                    modified_answer\n",
    "                )\n",
    "\n",
    "                \n",
    "                if old_citation_num in item.get('new_citations', []):\n",
    "                    idx = item['new_citations'].index(old_citation_num)\n",
    "                    ctx = item['new_used_contexts'][idx]\n",
    "                    updated_citation_contexts[cluster_id][new_citation_num] = ctx\n",
    "\n",
    "            modified_answers[cluster_id].append(modified_answer)\n",
    "\n",
    "    \n",
    "    final_output = {}\n",
    "\n",
    "    for cluster_id, answers in modified_answers.items():\n",
    "        text_to_summarize = \"\\n\\n\".join(answers)\n",
    "        custom_prompt = prompt_template.format(text_to_integrate=text_to_summarize)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in combining text.\"},\n",
    "                    {\"role\": \"user\", \"content\": custom_prompt}\n",
    "                ],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            summary = response.choices[0].message.content.strip()\n",
    "            \n",
    "            prompt_title = \"\"\n",
    "            final_output[cluster_id] = {\n",
    "                \"summary\": summary,\n",
    "                \"used_contexts\": updated_citation_contexts[cluster_id]\n",
    "            }\n",
    "            print(f\"Successfully summarized cluster {cluster_id} for {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error: Could not summarize due to {e}\"\n",
    "            final_output[cluster_id] = {\n",
    "                \"summary\": error_message,\n",
    "                \"used_contexts\": updated_citation_contexts[cluster_id]\n",
    "            }\n",
    "            print(f\"An error occurred while summarizing cluster {cluster_id} for {file_name}: {e}\")\n",
    "\n",
    "   \n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_output, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Successfully saved summary for {file_name} to {output_filename}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not write to file {output_filename}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b604c58",
   "metadata": {},
   "source": [
    "# Generate headline for the summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e813b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c47e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed summary_Indonesia_Floods and volcanic activity in Indonesia-Week 20 2024.json\n",
      "Processed summary_Jamaica_Hurricane Beryl-Week 28 2024.json\n",
      "Processed summary_Ukraine_Ukraine-Week 23 2024.json\n",
      "Processed summary_United Kingdom_UK riots-Week 32 2024.json\n",
      "Processed summary_Israel_Israel-Hamas war-Week 19 2024.json\n",
      "Processed summary_India_LandslideFloods-Week 31 2024.json\n",
      "Processed summary_Israel_Israel_Palestine_confilct-Week 40 2024.json\n",
      "Processed summary_Afghanistan_Afghanistan Floods-Week 21 2024.json\n",
      "Processed summary_Sudan_Sudan conflict-Week 34 2024.json\n",
      "Processed summary_Nigeria_Flooding in Nigeria-Week 37 2024.json\n",
      "Processed summary_Haiti_Gang violence and humanitarian crisis in Haiti-Week 40 2024.json\n",
      "Processed summary_Pakistan_Monsoon floods and rains in Pakistan-Week 31 2024.json\n",
      "Processed summary_Bangladesh_Cyclone Remal-Week 21 2024.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openaikey)\n",
    "\n",
    "title_prompt = \"\"\"You are creating a title for a situational report.\n",
    "\n",
    "Read the following summary and generate a title that:\n",
    "- Clearly identifies the situation, topic, or issue being reported\n",
    "- Is appropriate for a professional situational report (SITREP style)\n",
    "- Is direct and informative (8-12 words)\n",
    "- Uses clear, actionable language suitable for decision-makers\n",
    "- Does not include meta-phrases like \"Report on\" or \"Summary of\"\n",
    "\n",
    "Summary:\n",
    "{summary_text}\n",
    "\n",
    "Return only the title, nothing else.\"\"\"\n",
    "\n",
    "json_files = [f for f in os.listdir(output_path) if f.startswith('summary_') and f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    filepath = os.path.join(output_path, file)\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for cluster_id, cluster_data in data.items():\n",
    "        if 'title' not in cluster_data:\n",
    "            summary = cluster_data.get('summary', '')\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": title_prompt.format(summary_text=summary)}],\n",
    "                temperature=0.0\n",
    "            )\n",
    "            \n",
    "            cluster_data['title'] = response.choices[0].message.content.strip()\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Processed {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35dae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_timing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
